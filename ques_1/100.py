# -*- coding: utf-8 -*-
"""100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uE56OId9CCGCJ9e7kdHaX5STCjvAg5Ha
"""

import numpy as np
import pandas as pd
import glob

file_folder = r"hindi.txt"
file =  open(file_folder,"rb")
tex = file.read()

terms = []
truth =[]
for word in tex.decode(errors = 'replace').split('\n'):
  temp = []
  word = word.split(",")
  temp.append(word[0])
  temp.append(word[1])
  terms.append(temp)
  truth.append(word[2].split('\r')[0])

truth



terms[64]

"""**GLOV**"""

import pandas as pd
df = pd.read_csv(r"hi/100/glove/hi-d100-glove.txt",sep = " ",encoding = "utf-8",encoding_errors = 'ignore',header = None)

glov_100_acc  = []
for word in tex.decode(errors = 'replace').split('\n'):
    word = word.split("\t")

    a_word = word[0]
    temp = df[df.iloc[:,0] == a_word]
    
    aa = temp.iloc[:,[i for i in range(1,101)]]
    
    aa= aa.T
    aa = list(aa.iloc[:,0])
    b_word =  word[1]
    temp = df[df.iloc[:,0] == b_word]
    bb = temp.iloc[:,[i for i in range(1,101)]]
    bb = bb.T
    bb = list(bb.iloc[:,0])
    a = np.sum(np.dot(aa,bb))
    b = 0 
    for i in range(len(aa)):
      b = b + aa[i]*aa[i]
    b = b**.5
    c = 0
    for i in range(len(bb)):
      c = c + bb[i]*bb[i]
    c = c**.5
    x = a/(b*c)
    glov_100_acc.append(x)

#import pickle
#with open('/content/drive/MyDrive/100/100_glow.pkl','wb') as file:
    #pickle.dump(glov_100_acc,file)
    #file.close()

"""**CBow**"""

from gensim.models import Word2Vec
from gensim.models import FastText
cbow_mod = Word2Vec.load("hi/100/cbow/hi-d100-m2-cbow.model")

cbow_100_acc = []
for i in terms:
    aa = cbow_mod.wv[i[0]]
    bb = cbow_mod.wv[i[1]]
    a = np.sum(np.dot(aa,bb))
    b = 0 
    for i in range(len(aa)):
      b = b + aa[i]*aa[i]
    b = b**.5
    c = 0
    for i in range(len(bb)):
      c = c + bb[i]*bb[i]
    c = c**.5
    x = a/(b*c)
    cbow_100_acc.append(x)

cbow_100_acc

#import pickle
#with open('/100/100_cbow.pkl','wb') as file:
    #pickle.dump(cbow_100_acc,file)
    #file.close()



"""**skip gram**"""

from gensim.models import Word2Vec
from gensim.models import FastText
skipg_mod = Word2Vec.load("hi/100/sg/hi-d100-m2-sg.model")

skip_100_acc = []
for i in terms:
    aa = skipg_mod.wv[i[0]]
    bb = skipg_mod.wv[i[1]]
    a = np.sum(np.dot(aa,bb))
    b = 0 
    for i in range(len(aa)):
      b = b + aa[i]*aa[i]
    b = b**.5
    c = 0
    for i in range(len(bb)):
      c = c + bb[i]*bb[i]
    c = c**.5
    x = a/(b*c)
    skip_100_acc.append(x)

#import pickle
#with open('/content/drive/MyDrive/100/100_skip.pkl','wb') as file:
    #pickle.dump(skip_100_acc,file)
    #file.close()

"""**skip gram**

**fast text**
"""

from gensim.models import FastText
fast_mod = FastText.load("hi/100/fasttext/hi-d100-m2-fasttext.model")

fast_100_acc = []
for i in terms:
    aa = fast_mod.wv[i[0]]
    bb = fast_mod.wv[i[1]]
    a = np.sum(np.dot(aa,bb))
    b = 0 
    for i in range(len(aa)):
      b = b + aa[i]*aa[i]
    b = b**.5
    c = 0
    for i in range(len(bb)):
      c = c + bb[i]*bb[i]
    c = c**.5
    x = a/(b*c)
    fast_100_acc.append(x)

#import pickle
#with open('/content/drive/MyDrive/100/100_fast.pkl','wb') as file:
    #pickle.dump(fast_100_acc,file)
    #file.close()

"""glov accuracy"""

import pickle
with open("100_glow.pkl",'rb') as f:
  glov_100_acc = pickle.load(f)
  f.close()

print('accuracy test for glov')
thre =  [.4,.5,.6,.7,.8]
for i in thre:
  df = pd.DataFrame({'Word1':'','Word2':'','Similarity Score':'','Ground Truth':'','Label':''},index=[0])
  k = 0
  for j in range(len(glov_100_acc)):
    if(float(truth[j]) > 10*i):
      if(glov_100_acc[j] > i):
        x =1
        k = k+x
    else:
      if(glov_100_acc[j] <= 10*i):
        x =1
        k = k+x
  k = k /len(truth)
  temp = pd.DataFrame({'Word1':'accuracy','Word2':'','Similarity Score':'','Ground Truth':'','Label':k},index =[0])
  df = pd.concat([df,temp],axis = 0)
  df.to_csv('Q1_glov100_similarity_' + str(i) + '.csv')
  print("accuracy for threshold value" + " " + str(i),k )

"""cbow accuracy"""

import pickle
with open("100_cbow.pkl",'rb') as f:
  cbow_100_acc = pickle.load(f)
  f.close()

print('accuracy test for cbow')
thre =  [.4,.5,.6,.7,.8]
for i in thre:
  df = pd.DataFrame({'Word1':'','Word2':'','Similarity Score':'','Ground Truth':'','Label':''},index=[0])
  k = 0
  for j in range(len(cbow_100_acc)):
    if(float(truth[j]) > 10*i):
      if(cbow_100_acc[j] > i):
        x =1
        k = k+x
    else:
      if(cbow_100_acc[j] <= 10*i):
        x =1
        k = k+x
  k = k /len(truth)
  temp = pd.DataFrame({'Word1':'accuracy','Word2':'','Similarity Score':'','Ground Truth':'','Label':k},index =[0])
  df = pd.concat([df,temp],axis = 0)
  df.to_csv('Q1_cbow100_similarity_' + str(i) + '.csv')
  print("accuracy for threshold value" + " " + str(i),k )

"""sg"""

import pickle
with open("100_skip.pkl",'rb') as f:
  sg_100_acc = pickle.load(f)
  f.close()

print('accuracy test for sg')
thre =  [.4,.5,.6,.7,.8]
for i in thre:
  df = pd.DataFrame({'Word1':'','Word2':'','Similarity Score':'','Ground Truth':'','Label':''},index=[0])
  
  k = 0
  for j in range(len(sg_100_acc)):
    if(float(truth[j]) > 10*i):
      if(sg_100_acc[j] > i):
      
        x =1
        k = k+x
    else:
      if(sg_100_acc[j] <= 10*i):
        x =1
        k = k+x
  k = k /len(truth)
  temp = pd.DataFrame({'Word1':'accuracy','Word2':'','Similarity Score':'','Ground Truth':'','Label':k},index =[0])
  df = pd.concat([df,temp],axis = 0)
  df.to_csv('Q1_sg100_similarity_' + str(i) + '.csv')
  print("accuracy for threshold value" + " " + str(i),k )

"""fast text"""

import pickle
with open("100_fast.pkl",'rb') as f:
  fast_100_acc = pickle.load(f)
  f.close()

print('accuracy test for fasttext')
thre =  [.4,.5,.6,.7,.8]
for i in thre:
  k = 0
  df = pd.DataFrame({'Word1':'','Word2':'','Similarity Score':'','Ground Truth':'','Label':''},index=[0])
  for j in range(len(fast_100_acc)):
    if(float(truth[j]) > 10*i):
      if(fast_100_acc[j] > i):
        x =1
        k = k+x
    else:
      if(fast_100_acc[j] <= 10*i):
        x =1
        k = k+x
  k = k /len(truth)
  temp = pd.DataFrame({'Word1':'accuracy','Word2':'','Similarity Score':'','Ground Truth':'','Label':k},index =[0])
  df = pd.concat([df,temp],axis = 0)
  df.to_csv('Q1_fasttext100_similarity_' + str(i) + '.csv')
  print("accuracy for threshold value" + " " + str(i),k )